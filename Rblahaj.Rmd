---
title: "Selenium BLÃ…HAJ Scraper"
subtitle: "RStudio Notebook"
author: "Ari Ghasemian"
date: "4/20/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# import R packages
library(tidyverse)
library(reticulate)
reticulate::use_condaenv("blahaj", required = TRUE)
```

```{python}
# import python packages
import json, time, re
# selenium 4
from selenium import webdriver
from selenium.common.exceptions import *
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
```

```{python}
# set up Chrome webdriver with Selenium
# use Webdriver Manager for Python
# Start the driver 
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument('--window-size=1920,1080')
options.add_argument("--no-sandbox")
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(
  service=ChromeService(ChromeDriverManager().install()),
  options=options
)
```

```{python}
# input URL for IKEA article
URL = 'https://www.ikea.com/us/en/p/blahaj-soft-toy-shark-90373590/'
```

```{python}
# navigate to the URL for the product
driver.get(URL)
time.sleep(5)
```

```{python}
# accept cookies (ensures smooth operation)
try:
  driver.find_element(By.ID, "onetrust-accept-btn-handler").click()
except NoSuchElementException:
  pass
```

```{python}
# open the Reviews pane
driver.find_element(By.CLASS_NAME, "pip-chunky-header__reviews").click()
time.sleep(5)
```

```{python}
# output the results as a list of lists
list_of_rows = []
cols = ["rating", "date", "name", "location", "title", "review_text"]
```

```{python}
# loop over each page of reviews

# check whether there are more pages to loop over
keep_going = True

while keep_going == True:
  time.sleep(5)
  page_reviews = driver.find_elements(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__review")

  for review in page_reviews:
    # the rating (number of stars)
    rating = len(review.find_elements(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-star-bar__star--filled"))

    # the date of the review
    date = review.find_element(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__review-date").text

    # the name of the reviewer
    name_loc = review.find_element(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__reviewer-name").text
    
    name, location = name_loc.split('\n- ')
    
    # sometimes there is no title
    try:
      # the title
      title = review.find_element(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__review-title").text
    except NoSuchElementException:
      title = ''
    
    # the review text
    review_text = review.find_element(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__review-text").text
    
    # also scrape the ratings and reviews "categories"?
    # i.e. Value for money, Product quality, Appearance, Works as expected
    # (each is a value 1-5
    
    
    # put it all together
    row = [rating, date, name, location, title, review_text]
    list_of_rows.append(row)
    
  # is this the last page?
  # if the next page arrow button is not clickable
  next_page = driver.find_elements(By.CLASS_NAME, "ugc-rr-pip-fe-ratings-and-reviews__pagination-button")[1]
  if next_page.is_enabled():
    next_page.click()
  else:
    keep_going = False
```

```{python}
# save memory
driver.close()
driver.quit()
```

```{python}
print(len(list_of_rows))
```

```{r}
# transform the output from python list of lists to R data frame
list_of_rows <- t(sapply(py$list_of_rows, unlist))
colnames(list_of_rows) <- py$cols
data <- as_tibble(list_of_rows) %>%
  mutate(
    rating = as.integer(rating),
    date = mdy(date)
  )
glimpse(data)
```

```{r}
# save data
save(data, file="shiny_blahaj/output.RData")
```
